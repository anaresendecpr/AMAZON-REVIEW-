# -*- coding: utf-8 -*-
"""MetaData.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gR7trD4xoW4eO3KOBeOo_hHtm4ognvTg
"""

#Basic libraries
import pandas as pd 
import numpy as np 
import ast
import csv 
import re
import string

from google.colab import drive
drive.mount("/content/drive", force_remount = True)
meta = pd.read_csv ("/content/drive/MyDrive/Takeaway/metadata_category_clothing_shoes_and_jewelry_only.csv")

"""## **Data Exploration and Cleasing**"""

clean_meta=meta.copy()
clean_meta.isnull().sum()

clean_meta.head()

clean_meta.describe()

clean_meta.info()

#Treating null values and dropping unnecessary collumns

clean_meta['title']=clean_meta['title'].fillna('undefined')
clean_meta['brand']=clean_meta['brand'].fillna('undefined')

# I am replacing null values for -1 taking into account the assuption that when the reviewer bought the product it could be a sale, discount etc.. and the reviwer paid less for the product. 

clean_meta['price']=clean_meta['price'].fillna(-1)
clean_meta=clean_meta.drop(['imurl', 'description', 'categories'], axis=1)

clean_meta.isnull().sum()

#Removing noise from brand and title

def cleaning_text(text):
    text = re.sub('\[.*?\]', '', text)
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)
    return text
    
clean_meta['brand']=clean_meta['brand'].apply(lambda x:cleaning_text(x))
clean_meta['title']=clean_meta['title'].apply(lambda x:cleaning_text(x))
clean_meta.head()

"""## **Data Processing**"""

#Separating Main Categories from rank position in order to analyse categories relationship with review

def key(val):
    as_list = list(ast.literal_eval(str(val)).keys())
    return as_list[0] if as_list else ''

def value(val):
    as_list = list(ast.literal_eval(str(val)).values())
    return as_list[0] if as_list else None

clean_meta =clean_meta.dropna(subset=['salesrank'])
clean_meta['mainCategories'] = clean_meta['salesrank'].map(key)
clean_meta['rank'] = clean_meta['salesrank'].map(value)
clean_meta=clean_meta.drop(['salesrank'], axis=1)

# extracting column related from main data

meta['related']=meta['related'].fillna('None')

dic = {}
dic['metadateId']=[]
dic['asin']=[]
dic['type']=[]
dic['relatedId']=[]

for index, row in meta.iterrows():
    valS = row['related']
    if valS is not None and  valS != 'None':
      # print(valS)
      val = ast.literal_eval(valS)
      also_viewed = val.get('also_viewed')
      if also_viewed is not None:
          for i in also_viewed:
            dic['metadateId'].append(row['metadataid'])
            dic['asin'].append(row['asin'])
            dic['type'].append("also_viewed")
            dic['relatedId'].append( i)

      also_bought = val.get('also_bought')      
      if also_bought is not None:
          for i in also_bought:
            dic['metadateId'].append(row['metadataid'])            
            dic['asin'].append(row['asin'])
            dic['type'].append("also_bought")
            dic['relatedId'].append( i)

      bought_together = val.get('bought_together')      
      if bought_together is not None:
          for i in bought_together:
            dic['metadateId'].append(row['metadataid'])            
            dic['asin'].append(row['asin'])
            dic['type'].append("bought_together")
            dic['relatedId'].append( i)

df_marks = pd.DataFrame(dic)          
print(df_marks)

#dropping collumn related
clean_meta=clean_meta.drop([ 'related'], axis=1)

clean_meta['price']= clean_meta['price'].round(2) 
clean_meta['rank']= clean_meta['rank'].round(2)

#checking for nulls 
df_marks.isnull().sum()

clean_meta.to_csv(r'/content/drive/MyDrive/Takeaway/clean_meta.csv', index = False, sep=';', decimal=',')

#Saving csv 


df_marks.to_csv(r'/content/drive/MyDrive/Takeaway/related.csv', index = False, )